#!/usr/bin/env python3
"""
Test script for the REVISED ENRICHMENT FLOW:
- Admin fields are protected from LLM modification
- OpenAI generates right_answer field
- LLMs only enrich metadata fields
"""

import sys
import os
sys.path.append('/app/backend')

import asyncio
from database import SessionLocal, Question, Topic
from llm_enrichment import LLMEnrichmentService
import json
import traceback

async def test_revised_enrichment_flow():
    """Test the revised enrichment flow with admin field protection"""
    
    print("üß™ Testing REVISED ENRICHMENT FLOW")
    print("=" * 70)
    print("üìã Flow: Admin fields protected ‚Üí OpenAI generates right_answer ‚Üí LLMs enrich metadata")
    print("=" * 70)
    
    try:
        db = SessionLocal()
        enrichment_service = LLMEnrichmentService()
        
        # Test 1: Create a test question with admin-provided fields
        print("\nüìã Test 1: Creating test question with admin fields...")
        
        # Find a topic
        topic = db.query(Topic).first()
        if not topic:
            print("‚ùå No topics found in database")
            return False
        
        # Create test question with admin-provided content
        test_question = Question(
            topic_id=topic.id,
            subcategory="Time‚ÄìSpeed‚ÄìDistance (TSD)",
            type_of_question="Speed Calculation",
            # ADMIN-PROTECTED FIELDS
            stem="A car travels 120 km in 2 hours. What is its speed?",
            answer="The speed is 60 km/h",  # Admin provided
            solution_approach="Use the formula: Speed = Distance / Time",  # Admin provided  
            detailed_solution="Given: Distance = 120 km, Time = 2 hours\nSpeed = Distance / Time = 120 / 2 = 60 km/h",  # Admin provided
            principle_to_remember="Speed = Distance / Time is the fundamental formula",  # Admin provided
            image_url="https://example.com/speed-diagram.png",  # Admin provided
            # right_answer will be generated by OpenAI
            source="Test Admin"
        )
        
        db.add(test_question)
        db.commit()
        db.refresh(test_question)
        
        print(f"‚úÖ Test question created with ID: {test_question.id}")
        print(f"   - Admin stem: {test_question.stem}")
        print(f"   - Admin answer: {test_question.answer}")
        print(f"   - Admin solution_approach: {test_question.solution_approach}")
        print(f"   - Right answer before enrichment: {test_question.right_answer}")
        
        # Test 2: Run the revised enrichment process
        print("\nüìã Test 2: Running revised enrichment process...")
        
        original_fields = {
            "stem": test_question.stem,
            "answer": test_question.answer,
            "solution_approach": test_question.solution_approach,
            "detailed_solution": test_question.detailed_solution,
            "principle_to_remember": test_question.principle_to_remember,
            "image_url": test_question.image_url
        }
        
        enrichment_result = await enrichment_service.enrich_question_automatically(test_question, db)
        
        # Refresh question to get updated data
        db.refresh(test_question)
        
        print(f"Enrichment result: {enrichment_result}")
        
        # Test 3: Verify admin fields are protected
        print("\nüìã Test 3: Verifying admin field protection...")
        
        protected_fields_intact = True
        for field_name, original_value in original_fields.items():
            current_value = getattr(test_question, field_name)
            if current_value != original_value:
                print(f"‚ùå PROTECTED FIELD MODIFIED: {field_name}")
                print(f"   Original: {original_value}")
                print(f"   Current:  {current_value}")
                protected_fields_intact = False
            else:
                print(f"‚úÖ Protected field intact: {field_name}")
        
        # Test 4: Verify right_answer was generated
        print("\nüìã Test 4: Verifying right_answer generation...")
        
        if test_question.right_answer:
            print(f"‚úÖ Right answer generated: {test_question.right_answer}")
        else:
            print("‚ùå Right answer was not generated")
        
        # Test 5: Verify metadata fields were enriched
        print("\nüìã Test 5: Verifying metadata enrichment...")
        
        metadata_fields = {
            "difficulty_score": test_question.difficulty_score,
            "difficulty_band": test_question.difficulty_band,
            "frequency_band": test_question.frequency_band,
            "learning_impact": test_question.learning_impact,
            "importance_index": test_question.importance_index
        }
        
        metadata_enriched = False
        for field_name, value in metadata_fields.items():
            if value is not None:
                print(f"‚úÖ Metadata enriched: {field_name} = {value}")
                metadata_enriched = True
            else:
                print(f"‚ö†Ô∏è  Metadata not set: {field_name}")
        
        # Test 6: Verify MCQ options were generated
        print("\nüìã Test 6: Verifying MCQ options generation...")
        
        if test_question.mcq_options:
            try:
                mcq_data = json.loads(test_question.mcq_options)
                print(f"‚úÖ MCQ options generated: {mcq_data}")
            except:
                print(f"‚ö†Ô∏è  MCQ options present but not valid JSON: {test_question.mcq_options}")
        else:
            print("‚ö†Ô∏è  MCQ options not generated")
        
        # Clean up test question
        db.delete(test_question)
        db.commit()
        
        db.close()
        
        # Final assessment
        print("\n" + "=" * 70)
        print("üèÜ REVISED ENRICHMENT FLOW TEST RESULTS:")
        print(f"‚úÖ Admin fields protected: {protected_fields_intact}")
        print(f"‚úÖ Right answer generated: {bool(test_question.right_answer)}")
        print(f"‚úÖ Metadata enriched: {metadata_enriched}")
        print(f"‚úÖ Enrichment successful: {enrichment_result.get('success', False)}")
        
        success = (protected_fields_intact and 
                  bool(test_question.right_answer) and 
                  metadata_enriched and 
                  enrichment_result.get('success', False))
        
        return success
        
    except Exception as e:
        print(f"‚ùå Error during testing: {str(e)}")
        print(f"‚ùå Traceback: {traceback.format_exc()}")
        return False

async def test_openai_right_answer_generation():
    """Test OpenAI right_answer generation specifically"""
    
    print("\nüß† Testing OpenAI right_answer generation specifically...")
    print("=" * 70)
    
    try:
        enrichment_service = LLMEnrichmentService()
        
        test_questions = [
            "What is 25% of 200?",
            "A train travels 300 km in 5 hours. What is its speed?",
            "If the cost price is ‚Çπ100 and selling price is ‚Çπ120, what is the profit percentage?"
        ]
        
        for i, question_stem in enumerate(test_questions, 1):
            print(f"\nüìã Test {i}: {question_stem}")
            
            right_answer = await enrichment_service._generate_right_answer_with_openai(question_stem)
            
            if right_answer:
                print(f"‚úÖ Generated answer: {right_answer}")
            else:
                print("‚ùå Failed to generate answer")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error testing OpenAI generation: {str(e)}")
        return False

if __name__ == "__main__":
    print("üöÄ REVISED ENRICHMENT FLOW TEST SUITE")
    print("=" * 70)
    print("Testing the new flow where admin fields are PROTECTED")
    print("and only metadata fields are enriched by LLMs")
    print("=" * 70)
    
    async def run_all_tests():
        # Test the main revised flow
        main_test_success = await test_revised_enrichment_flow()
        
        # Test OpenAI right_answer generation specifically  
        openai_test_success = await test_openai_right_answer_generation()
        
        print("\n" + "=" * 70)
        print("üéâ FINAL TEST RESULTS:")
        print(f"‚úÖ Revised enrichment flow: {'PASSED' if main_test_success else 'FAILED'}")
        print(f"‚úÖ OpenAI right_answer generation: {'PASSED' if openai_test_success else 'FAILED'}")
        
        if main_test_success and openai_test_success:
            print("\nüéâ ALL TESTS PASSED! The revised enrichment flow is working correctly.")
            print("\nüìã Confirmed functionality:")
            print("   - Admin fields (stem, answer, solution_approach, detailed_solution, principle_to_remember, image_url) are PROTECTED")
            print("   - OpenAI generates right_answer field based on question stem")
            print("   - LLMs enrich only metadata fields (difficulty, frequency, etc.)")
            print("   - MCQ options are generated without affecting admin content")
        else:
            print("\n‚ùå Some tests failed. Please check the error messages above.")
            sys.exit(1)
    
    # Run the async tests
    asyncio.run(run_all_tests())