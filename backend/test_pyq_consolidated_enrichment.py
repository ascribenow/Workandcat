#!/usr/bin/env python3
"""
Test PYQ Consolidated Enrichment Implementation
"""

import asyncio
import os
from pyq_enrichment_service import pyq_enrichment_service

async def test_pyq_consolidated_enrichment():
    """Test the new consolidated PYQ enrichment implementation"""
    
    print("🧪 Testing PYQ Consolidated Enrichment (Single LLM Call)")
    print("=" * 70)
    
    # Test sample PYQ question
    test_stem = """
    A train travels 120 km in 2 hours. Another train travels 180 km in 3 hours. 
    What is the ratio of their speeds?
    """
    
    print(f"📚 Test Question: {test_stem.strip()}")
    print("\n🚀 Starting consolidated enrichment...")
    
    try:
        # Test the consolidated enrichment
        result = await pyq_enrichment_service.enrich_pyq_question(
            stem=test_stem.strip(),
            current_answer="To be generated by LLM"
        )
        
        if result["success"]:
            enrichment = result["enrichment_data"]
            
            print("\n✅ CONSOLIDATED ENRICHMENT SUCCESS!")
            print("=" * 50)
            
            # Stage 1-4 Results (from single LLM call)
            print("🚀 STAGE 1-4 CONSOLIDATED RESULTS:")
            print(f"📝 Answer: {enrichment.get('answer', 'N/A')[:100]}...")
            print(f"📂 Category: {enrichment.get('category', 'N/A')}")
            print(f"📋 Subcategory: {enrichment.get('subcategory', 'N/A')}")
            print(f"📄 Type: {enrichment.get('type_of_question', 'N/A')}")
            print(f"⚖️ Difficulty: {enrichment.get('difficulty_band', 'N/A')} ({enrichment.get('difficulty_score', 'N/A')})")
            print(f"🧬 Solution Method: {enrichment.get('solution_method', 'N/A')}")
            print(f"🏗️ Problem Structure: {enrichment.get('problem_structure', 'N/A')}")
            
            # Stage 5 Results (semantic matching + verification)
            print("\n🔍 STAGE 5 RESULTS:")
            print(f"✅ Quality Verified: {enrichment.get('quality_verified', False)}")
            print(f"📊 Status: {enrichment.get('concept_extraction_status', 'N/A')}")
            
            # Performance metrics
            print(f"\n📈 PERFORMANCE:")
            print(f"   Processing: {result.get('processing_time', 'N/A')}")
            print(f"   Fields Generated: {len(enrichment)}")
            
            # Show efficiency improvement
            print(f"\n🎯 EFFICIENCY GAINS:")
            print(f"   OLD APPROACH: 4 separate LLM calls + semantic matching + verification")
            print(f"   NEW APPROACH: 1 consolidated LLM call + semantic matching + verification")
            print(f"   IMPROVEMENT: ~75% reduction in LLM API calls")
            
        else:
            print(f"❌ Enrichment failed: {result.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"❌ Test error: {e}")
    
    print("\n🎉 PYQ Consolidated Enrichment Test Complete!")

if __name__ == "__main__":
    # Set OpenAI API key for testing
    if not os.getenv('OPENAI_API_KEY'):
        print("⚠️ OPENAI_API_KEY not set - tests may fail")
    
    asyncio.run(test_pyq_consolidated_enrichment())