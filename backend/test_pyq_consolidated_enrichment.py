#!/usr/bin/env python3
"""
Test PYQ Consolidated Enrichment Implementation
"""

import asyncio
import os
from pyq_enrichment_service import pyq_enrichment_service

async def test_pyq_consolidated_enrichment():
    """Test the new consolidated PYQ enrichment implementation"""
    
    print("ğŸ§ª Testing PYQ Consolidated Enrichment (Single LLM Call)")
    print("=" * 70)
    
    # Test sample PYQ question
    test_stem = """
    A train travels 120 km in 2 hours. Another train travels 180 km in 3 hours. 
    What is the ratio of their speeds?
    """
    
    print(f"ğŸ“š Test Question: {test_stem.strip()}")
    print("\nğŸš€ Starting consolidated enrichment...")
    
    try:
        # Test the consolidated enrichment
        result = await pyq_enrichment_service.enrich_pyq_question(
            stem=test_stem.strip(),
            current_answer="To be generated by LLM"
        )
        
        if result["success"]:
            enrichment = result["enrichment_data"]
            
            print("\nâœ… CONSOLIDATED ENRICHMENT SUCCESS!")
            print("=" * 50)
            
            # Stage 1-4 Results (from single LLM call)
            print("ğŸš€ STAGE 1-4 CONSOLIDATED RESULTS:")
            print(f"ğŸ“ Answer: {enrichment.get('answer', 'N/A')[:100]}...")
            print(f"ğŸ“‚ Category: {enrichment.get('category', 'N/A')}")
            print(f"ğŸ“‹ Subcategory: {enrichment.get('subcategory', 'N/A')}")
            print(f"ğŸ“„ Type: {enrichment.get('type_of_question', 'N/A')}")
            print(f"âš–ï¸ Difficulty: {enrichment.get('difficulty_band', 'N/A')} ({enrichment.get('difficulty_score', 'N/A')})")
            print(f"ğŸ§¬ Solution Method: {enrichment.get('solution_method', 'N/A')}")
            print(f"ğŸ—ï¸ Problem Structure: {enrichment.get('problem_structure', 'N/A')}")
            
            # Stage 5 Results (semantic matching + verification)
            print("\nğŸ” STAGE 5 RESULTS:")
            print(f"âœ… Quality Verified: {enrichment.get('quality_verified', False)}")
            print(f"ğŸ“Š Status: {enrichment.get('concept_extraction_status', 'N/A')}")
            
            # Performance metrics
            print(f"\nğŸ“ˆ PERFORMANCE:")
            print(f"   Processing: {result.get('processing_time', 'N/A')}")
            print(f"   Fields Generated: {len(enrichment)}")
            
            # Show efficiency improvement
            print(f"\nğŸ¯ EFFICIENCY GAINS:")
            print(f"   OLD APPROACH: 4 separate LLM calls + semantic matching + verification")
            print(f"   NEW APPROACH: 1 consolidated LLM call + semantic matching + verification")
            print(f"   IMPROVEMENT: ~75% reduction in LLM API calls")
            
        else:
            print(f"âŒ Enrichment failed: {result.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"âŒ Test error: {e}")
    
    print("\nğŸ‰ PYQ Consolidated Enrichment Test Complete!")

if __name__ == "__main__":
    # Set OpenAI API key for testing
    if not os.getenv('OPENAI_API_KEY'):
        print("âš ï¸ OPENAI_API_KEY not set - tests may fail")
    
    asyncio.run(test_pyq_consolidated_enrichment())